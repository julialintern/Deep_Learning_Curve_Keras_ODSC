{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2><center><font color='black'>   Taking a Deep-Learning Dive with Keras </font></center></h2>\n",
    "\n",
    "<img src='../imgs/Deep_Dive_Keras_3.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Nets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Snippet of a fully connected model\n",
    "<img src='../imgs/full_connect.png'/>\n",
    "\n",
    "### Snippet of RNN\n",
    "<img src='../imgs/rnn3.jpg'/>\n",
    "\n",
    "#### Our recurrence formula:\n",
    "$$s_t=f_W(s_{t-1},x_t)$$\n",
    "\n",
    "(where ht: new state, f~function with parameters W, ht-1: previous, \n",
    "h_t=tanh(Whh(ht-1) + Wxh(xt))\n",
    "yt=Why(h_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo-code example:  RNN for text 'generation' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Vocab_size =1000 \n",
    "hidden_layer=100\n",
    "\n",
    "# U ~ 100x 1000\n",
    "# V ~ 1000 x 100\n",
    "# W ~ 100 x 100 \n",
    "\n",
    "time_steps = 10   #  where time_steps are # of words in sample\n",
    "\n",
    "# define our state matrix:\n",
    "# s = 10 X 100\n",
    "\n",
    "# output\n",
    "# o = 1 x 1000\n",
    "\n",
    "for t in time_steps:\n",
    "    #  U[x[t]   ~ essentially a look-up for U\n",
    "    s[t]=np.tanh(U[x[t]] + np.dot(W,s[t-1]) \n",
    "    o[t] = softmax(V.dot(s[t]))\n",
    "                 \n",
    "## during backprop, we continue to update each matrix: U,V,W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN: Process Sequences\n",
    "\n",
    "<img src='imgs/rnn_one.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSTM  - Long Short Term Memory\n",
    "\n",
    "<img src='imgs/lstm_3_anno.png'/>\n",
    "<img src='imgs/lstm_eqn.png'/>\n",
    "\n",
    "[credits: Colah's Blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Reshape, Activation, Bidirectional,\\\n",
    "     SimpleRNN, GRU, LSTM, Convolution1D, MaxPooling1D, Merge, Dropout, Convolution2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from IPython.display import SVG\n",
    "\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Example: Text Classification\n",
    "\n",
    "- We'll work with reuter newswire to classification dataset.   \n",
    "- 46 classes\n",
    "- We will model this using RNNs, but first let's try with an ANN. \n",
    "\n",
    "#### Ex 1: Reuters newswire data via ANN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "1638400/2110848 [======================>.......] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "max_features = 2000\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(\n",
    "    num_words=max_features)\n",
    "maxlen = 10\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[324  27  56   2   2   5 192 510  17  12]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how our data is returned\n",
    "print(X_test[0])\n",
    "print(y_test[0])\n",
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.1011 - acc: 0.2611 - val_loss: 2.7102 - val_acc: 0.2110\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3135 - acc: 0.2477 - val_loss: 3.1247 - val_acc: 0.0441\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3714 - acc: 0.2534 - val_loss: 2.8647 - val_acc: 0.1638\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3333 - acc: 0.2554 - val_loss: 2.9718 - val_acc: 0.2110\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3508 - acc: 0.2532 - val_loss: 2.9016 - val_acc: 0.3620\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3698 - acc: 0.2462 - val_loss: 2.7145 - val_acc: 0.3620\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3725 - acc: 0.2532 - val_loss: 2.6893 - val_acc: 0.2159\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3689 - acc: 0.2509 - val_loss: 2.8402 - val_acc: 0.1371\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3798 - acc: 0.2477 - val_loss: 2.8309 - val_acc: 0.3620\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3467 - acc: 0.2531 - val_loss: 2.5593 - val_acc: 0.3620\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3882 - acc: 0.2462 - val_loss: 3.8529 - val_acc: 0.3620\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3766 - acc: 0.2505 - val_loss: 2.6264 - val_acc: 0.3620\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.4111 - acc: 0.2460 - val_loss: 3.2943 - val_acc: 0.3620\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3530 - acc: 0.2501 - val_loss: 3.0298 - val_acc: 0.0699\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.4072 - acc: 0.2478 - val_loss: 2.9755 - val_acc: 0.3620\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3611 - acc: 0.2463 - val_loss: 2.8332 - val_acc: 0.2110\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.4334 - acc: 0.2503 - val_loss: 3.2183 - val_acc: 0.3620\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.4556 - acc: 0.2470 - val_loss: 2.6861 - val_acc: 0.3620\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3998 - acc: 0.2501 - val_loss: 3.5082 - val_acc: 0.2110\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 0s - loss: 3.3903 - acc: 0.2481 - val_loss: 2.6794 - val_acc: 0.3620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117818e80>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Develop ANN Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=10, kernel_initializer='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, kernel_initializer='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(46, kernel_initializer='uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Momentum: gradient descent moves faster if gradient keeps pointing in the same direction\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cb=keras.callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=20, callbacks=[cb],\n",
    "          batch_size=32,validation_data=[X_test, y_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review score & loss results.  Thoughts ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex 2: Reuters newswire data via RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"377pt\" viewBox=\"0.00 0.00 337.93 377.00\" width=\"338pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 373)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-373 333.9277,-373 333.9277,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4788811256 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4788811256</title>\n",
       "<polygon fill=\"none\" points=\".0205,-324.5 .0205,-368.5 329.9072,-368.5 329.9072,-324.5 .0205,-324.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.8052\" y=\"-342.3\">embedding_4_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"197.5898,-324.5 197.5898,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.4243\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"197.5898,-346.5 253.2588,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.4243\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"253.2588,-324.5 253.2588,-368.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.583\" y=\"-353.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"253.2588,-346.5 329.9072,-346.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.583\" y=\"-331.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 4788812320 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4788812320</title>\n",
       "<polygon fill=\"none\" points=\"2.7344,-243.5 2.7344,-287.5 327.1934,-287.5 327.1934,-243.5 2.7344,-243.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.8052\" y=\"-261.3\">embedding_4: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"166.876,-243.5 166.876,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.7104\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"166.876,-265.5 222.5449,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.7104\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222.5449,-243.5 222.5449,-287.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.8691\" y=\"-272.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"222.5449,-265.5 327.1934,-265.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.8691\" y=\"-250.3\">(None, 10, 100)</text>\n",
       "</g>\n",
       "<!-- 4788811256&#45;&gt;4788812320 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4788811256-&gt;4788812320</title>\n",
       "<path d=\"M164.9639,-324.3664C164.9639,-316.1516 164.9639,-306.6579 164.9639,-297.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"168.464,-297.6068 164.9639,-287.6068 161.464,-297.6069 168.464,-297.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4788811536 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4788811536</title>\n",
       "<polygon fill=\"none\" points=\"0,-162.5 0,-206.5 329.9277,-206.5 329.9277,-162.5 0,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.8052\" y=\"-180.3\">simple_rnn_5: SimpleRNN</text>\n",
       "<polyline fill=\"none\" points=\"169.6104,-162.5 169.6104,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.4448\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"169.6104,-184.5 225.2793,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.4448\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"225.2793,-162.5 225.2793,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.6035\" y=\"-191.3\">(None, 10, 100)</text>\n",
       "<polyline fill=\"none\" points=\"225.2793,-184.5 329.9277,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.6035\" y=\"-169.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 4788812320&#45;&gt;4788811536 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4788812320-&gt;4788811536</title>\n",
       "<path d=\"M164.9639,-243.3664C164.9639,-235.1516 164.9639,-225.6579 164.9639,-216.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"168.464,-216.6068 164.9639,-206.6068 161.464,-216.6069 168.464,-216.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4774579280 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4774579280</title>\n",
       "<polygon fill=\"none\" points=\"46.6792,-81.5 46.6792,-125.5 283.2485,-125.5 283.2485,-81.5 46.6792,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.8052\" y=\"-99.3\">dense_7: Dense</text>\n",
       "<polyline fill=\"none\" points=\"150.9312,-81.5 150.9312,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.7656\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"150.9312,-103.5 206.6001,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.7656\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"206.6001,-81.5 206.6001,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.9243\" y=\"-110.3\">(None, 20)</text>\n",
       "<polyline fill=\"none\" points=\"206.6001,-103.5 283.2485,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.9243\" y=\"-88.3\">(None, 46)</text>\n",
       "</g>\n",
       "<!-- 4788811536&#45;&gt;4774579280 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4788811536-&gt;4774579280</title>\n",
       "<path d=\"M164.9639,-162.3664C164.9639,-154.1516 164.9639,-144.6579 164.9639,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"168.464,-135.6068 164.9639,-125.6068 161.464,-135.6069 168.464,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4774576648 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4774576648</title>\n",
       "<polygon fill=\"none\" points=\"23.3447,-.5 23.3447,-44.5 306.583,-44.5 306.583,-.5 23.3447,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.8052\" y=\"-18.3\">activation_7: Activation</text>\n",
       "<polyline fill=\"none\" points=\"174.2656,-.5 174.2656,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.1001\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"174.2656,-22.5 229.9346,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.1001\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"229.9346,-.5 229.9346,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268.2588\" y=\"-29.3\">(None, 46)</text>\n",
       "<polyline fill=\"none\" points=\"229.9346,-22.5 306.583,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268.2588\" y=\"-7.3\">(None, 46)</text>\n",
       "</g>\n",
       "<!-- 4774579280&#45;&gt;4774576648 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4774579280-&gt;4774576648</title>\n",
       "<path d=\"M164.9639,-81.3664C164.9639,-73.1516 164.9639,-63.6579 164.9639,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"168.464,-54.6068 164.9639,-44.6068 161.464,-54.6069 168.464,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "# This is the most basic kind of RNN!  We're using 20 units, \n",
    "# which somewhat reflects our \"memory\" of past events in a sequence\n",
    "model.add(Embedding(input_dim=max_features, output_dim=100, embeddings_initializer=\"glorot_uniform\", input_length=maxlen))\n",
    "# This is the most basic kind of RNN!  We're using 20 units, \n",
    "model.add(SimpleRNN(20, return_sequences=False))\n",
    "model.add(Dense(46))  # number of classes\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 2s - loss: 1.5753 - acc: 0.5950 - val_loss: 2.1755 - val_acc: 0.4448\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 2s - loss: 1.5533 - acc: 0.6006 - val_loss: 2.1883 - val_acc: 0.4466\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 2s - loss: 1.5340 - acc: 0.6074 - val_loss: 2.2049 - val_acc: 0.4448\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.5109 - acc: 0.6145 - val_loss: 2.2210 - val_acc: 0.4457\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - ETA: 0s - loss: 1.4878 - acc: 0.624 - 1s - loss: 1.4913 - acc: 0.6226 - val_loss: 2.2382 - val_acc: 0.4452\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.4703 - acc: 0.6318 - val_loss: 2.2546 - val_acc: 0.4448\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.4498 - acc: 0.6383 - val_loss: 2.2795 - val_acc: 0.4421\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.4293 - acc: 0.6440 - val_loss: 2.2943 - val_acc: 0.4564\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 2s - loss: 1.4094 - acc: 0.6522 - val_loss: 2.3178 - val_acc: 0.4439\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.3908 - acc: 0.6530 - val_loss: 2.3168 - val_acc: 0.4470\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.3720 - acc: 0.6592 - val_loss: 2.3343 - val_acc: 0.4452\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.3535 - acc: 0.6667 - val_loss: 2.3627 - val_acc: 0.4399\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 2s - loss: 1.3347 - acc: 0.6720 - val_loss: 2.3802 - val_acc: 0.4399\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.3171 - acc: 0.6765 - val_loss: 2.3975 - val_acc: 0.4390\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.3018 - acc: 0.6796 - val_loss: 2.4187 - val_acc: 0.4421\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.2848 - acc: 0.6868 - val_loss: 2.4485 - val_acc: 0.4359\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.2664 - acc: 0.6908 - val_loss: 2.4659 - val_acc: 0.4372\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.2512 - acc: 0.6956 - val_loss: 2.4798 - val_acc: 0.4435\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.2358 - acc: 0.7011 - val_loss: 2.4935 - val_acc: 0.4390\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 1s - loss: 1.2226 - acc: 0.7026 - val_loss: 2.5031 - val_acc: 0.4399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117339630>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refresh localhost: 9000\n",
    "cb=keras.callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "model.fit(X_train,y_train,epochs=20,\n",
    "         validation_data=(X_test,y_test),callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  What do you notice about the training results ?\n",
    "- 200% improvement over ANN. \n",
    "- Let's improve ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM  - Long Short Term Memory\n",
    "\n",
    "<img src='../imgs/lstm_3_anno.png'/>\n",
    "<img src='../imgs/lstm_eqn.png'/>\n",
    "\n",
    "[credits: Colah's Blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex 3: Last time with Reuters newswire via LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Along!\n",
    "\n",
    "1) Run the following LSTM model.     \n",
    "- We see a moderate improvement from our RNN model.  How can we improve this further? \n",
    "\n",
    "Hints: \n",
    "* Adjust # of memory units\n",
    "* Compare & contrast different optimizers\n",
    "* Shit-tab to read LSTM & Embedding DocStrings.  Experiment with other arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"377pt\" viewBox=\"0.00 0.00 337.89 377.00\" width=\"338pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 373)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-373 333.887,-373 333.887,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4639029512 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4639029512</title>\n",
       "<polygon fill=\"none\" points=\"0,-324.5 0,-368.5 329.887,-368.5 329.887,-324.5 0,-324.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-342.3\">embedding_1_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"197.569,-324.5 197.569,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.404\" y=\"-353.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"197.569,-346.5 253.238,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.404\" y=\"-331.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"253.238,-324.5 253.238,-368.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.562\" y=\"-353.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"253.238,-346.5 329.887,-346.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.562\" y=\"-331.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 4639029176 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4639029176</title>\n",
       "<polygon fill=\"none\" points=\"2.71387,-243.5 2.71387,-287.5 327.173,-287.5 327.173,-243.5 2.71387,-243.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.7847\" y=\"-261.3\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"166.855,-243.5 166.855,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.69\" y=\"-272.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"166.855,-265.5 222.524,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.69\" y=\"-250.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222.524,-243.5 222.524,-287.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.849\" y=\"-272.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"222.524,-265.5 327.173,-265.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.849\" y=\"-250.3\">(None, 10, 100)</text>\n",
       "</g>\n",
       "<!-- 4639029512&#45;&gt;4639029176 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4639029512-&gt;4639029176</title>\n",
       "<path d=\"M164.943,-324.329C164.943,-316.183 164.943,-306.699 164.943,-297.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"168.443,-297.729 164.943,-287.729 161.443,-297.729 168.443,-297.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4639029288 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4639029288</title>\n",
       "<polygon fill=\"none\" points=\"35.3623,-162.5 35.3623,-206.5 294.524,-206.5 294.524,-162.5 35.3623,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.7847\" y=\"-180.3\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"134.207,-162.5 134.207,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.042\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"134.207,-184.5 189.876,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.042\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"189.876,-162.5 189.876,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242.2\" y=\"-191.3\">(None, 10, 100)</text>\n",
       "<polyline fill=\"none\" points=\"189.876,-184.5 294.524,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242.2\" y=\"-169.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 4639029176&#45;&gt;4639029288 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4639029176-&gt;4639029288</title>\n",
       "<path d=\"M164.943,-243.329C164.943,-235.183 164.943,-225.699 164.943,-216.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"168.443,-216.729 164.943,-206.729 161.443,-216.729 168.443,-216.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4475540536 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4475540536</title>\n",
       "<polygon fill=\"none\" points=\"46.6587,-81.5 46.6587,-125.5 283.228,-125.5 283.228,-81.5 46.6587,-81.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-99.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"150.911,-81.5 150.911,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.745\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"150.911,-103.5 206.58,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.745\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"206.58,-81.5 206.58,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.904\" y=\"-110.3\">(None, 20)</text>\n",
       "<polyline fill=\"none\" points=\"206.58,-103.5 283.228,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"244.904\" y=\"-88.3\">(None, 46)</text>\n",
       "</g>\n",
       "<!-- 4639029288&#45;&gt;4475540536 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4639029288-&gt;4475540536</title>\n",
       "<path d=\"M164.943,-162.329C164.943,-154.183 164.943,-144.699 164.943,-135.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"168.443,-135.729 164.943,-125.729 161.443,-135.729 168.443,-135.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4693937120 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4693937120</title>\n",
       "<polygon fill=\"none\" points=\"23.3242,-0.5 23.3242,-44.5 306.562,-44.5 306.562,-0.5 23.3242,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7847\" y=\"-18.3\">activation_1: Activation</text>\n",
       "<polyline fill=\"none\" points=\"174.245,-0.5 174.245,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.08\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"174.245,-22.5 229.914,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202.08\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"229.914,-0.5 229.914,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268.238\" y=\"-29.3\">(None, 46)</text>\n",
       "<polyline fill=\"none\" points=\"229.914,-22.5 306.562,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268.238\" y=\"-7.3\">(None, 46)</text>\n",
       "</g>\n",
       "<!-- 4475540536&#45;&gt;4693937120 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4475540536-&gt;4693937120</title>\n",
       "<path d=\"M164.943,-81.3294C164.943,-73.1826 164.943,-63.6991 164.943,-54.7971\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"168.443,-54.729 164.943,-44.729 161.443,-54.729 168.443,-54.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st run through, LSTM with SGD\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=max_features, output_dim=100, embeddings_initializer=\"glorot_uniform\", input_length=maxlen))\n",
    "\n",
    "model.add(LSTM(20, return_sequences=False)) # again 20 'memory' units\n",
    "model.add(Dense(46))  # number of classes\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "np.random.seed(123)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refresh localhost: 9000\n",
    "cb=keras.callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "model.fit(X_train,y_train,epochs=20,\n",
    "         validation_data=(X_test,y_test),callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/learning_a.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2nd run through - let's just change the optimizer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=max_features, output_dim=100, embeddings_initializer=\"glorot_uniform\", input_length=maxlen))\n",
    "\n",
    "model.add(LSTM(20, return_sequences=False)) # again 20 'memory' units\n",
    "model.add(Dense(46))  # number of classes\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "np.random.seed(123)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 3s - loss: 2.6037 - acc: 0.3456 - val_loss: 2.1851 - val_acc: 0.3909\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 3s - loss: 2.1098 - acc: 0.4318 - val_loss: 2.0929 - val_acc: 0.4377\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 3s - loss: 2.0224 - acc: 0.4589 - val_loss: 2.0427 - val_acc: 0.4599\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.9702 - acc: 0.4667 - val_loss: 2.0125 - val_acc: 0.4675\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.9248 - acc: 0.4825 - val_loss: 1.9972 - val_acc: 0.4773\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.8895 - acc: 0.4994 - val_loss: 1.9769 - val_acc: 0.4858\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.8577 - acc: 0.5100 - val_loss: 1.9741 - val_acc: 0.4893\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.8327 - acc: 0.5135 - val_loss: 1.9712 - val_acc: 0.4907\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.8083 - acc: 0.5203 - val_loss: 1.9570 - val_acc: 0.4880\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.7863 - acc: 0.5285 - val_loss: 1.9648 - val_acc: 0.4911\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.7660 - acc: 0.5330 - val_loss: 1.9517 - val_acc: 0.4889\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.7483 - acc: 0.5363 - val_loss: 1.9483 - val_acc: 0.4947\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.7305 - acc: 0.5373 - val_loss: 1.9490 - val_acc: 0.4920\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.7164 - acc: 0.5425 - val_loss: 1.9478 - val_acc: 0.4924\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.6992 - acc: 0.5485 - val_loss: 1.9654 - val_acc: 0.4987\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.6843 - acc: 0.5521 - val_loss: 1.9523 - val_acc: 0.4960\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.6686 - acc: 0.5595 - val_loss: 1.9542 - val_acc: 0.4947\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.6529 - acc: 0.5629 - val_loss: 1.9522 - val_acc: 0.5049\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.6393 - acc: 0.5714 - val_loss: 1.9613 - val_acc: 0.5022\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 3s - loss: 1.6235 - acc: 0.5772 - val_loss: 1.9513 - val_acc: 0.5009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1204a2b38>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refresh localhost: 9000\n",
    "cb=keras.callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "model.fit(X_train,y_train,epochs=20,\n",
    "         validation_data=(X_test,y_test),callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/learning_b.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maxlen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2906d6dbfa9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"glorot_uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_W\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_U\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# again 20 'memory' units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'maxlen' is not defined"
     ]
    }
   ],
   "source": [
    "# 3rd run through - change # nodes of LSTM memory layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=max_features, output_dim=500, embeddings_initializer=\"glorot_uniform\", input_length=maxlen))\n",
    "\n",
    "model.add(LSTM(256, return_sequences=False, dropout_W=0.2, dropout_U=0.2)) # again 20 'memory' units\n",
    "model.add(Dense(46))  # number of classes\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "np.random.seed(123)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refresh localhost: 9000\n",
    "cb=keras.callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "\n",
    "model.fit(X_train,y_train,epochs=20,\n",
    "         validation_data=(X_test,y_test),callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../imgs/learning_c.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bidirectional Recurrent Neural Networks (RNN)\n",
    "- Bidirectionall RNNs simply connect in both directions\n",
    "- Thus, output can be dependent on both future and past inputs\n",
    "- Good for context around a word, for instance\n",
    "  - e.g. Named Entity Recognition, is this a \"person\" token?\n",
    "\n",
    "\n",
    "<img src=\"imgs/brnn_a.png\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 10  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "# Bidirectional LSTM!!!\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 53s - loss: 0.8155 - acc: 0.4984 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 73s - loss: 0.6935 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.5000.50\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 74s - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 69s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 71s - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13020bf98>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# about 5 minute runtime\n",
    "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# reset localhost:9000\n",
    "cb=keras.callbacks.RemoteMonitor(root='http://localhost:9000')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation with LSTM & shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 4583798\n",
      "\n",
      "\n",
      "\"act i\"\n",
      "\"scene i. london. the palace.\"\n",
      "\"enter king henry, lord john of lancaster, the earl of westmoreland, \n",
      "total chars: 44\n"
     ]
    }
   ],
   "source": [
    "file='../data/alllines.txt'  # read in shakespeare from our local file\n",
    "text = open(file).read().lower()\n",
    "print('corpus length:', len(text))\n",
    "print ('\\n')\n",
    "print (text[:108])\n",
    "\n",
    "# let's just take the first 500K\n",
    "text=text[:500000]\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 18), ('b', 19), ('c', 20), ('d', 21), ('e', 22), ('f', 23), ('g', 24)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(char_indices.items())[18:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 166654\n",
      "th brought us smooth and welcome news.\"\n",
      "\n",
      "\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "brought us smooth and welcome news.\"\n",
      "\"th\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step): #moving through by step size 3\n",
    "    sentences.append(text[i: i + maxlen]) # get 40 characters\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "\n",
    "print(sentences[999])\n",
    "print(next_chars[999])\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print(sentences[1000])\n",
    "print(next_chars[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape   # num sentences x sentence length x unique characters\n",
    "\n",
    "X[0][0]  # pulling out an observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "losses=[]\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "\n",
    "    start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Additional Challenges & Work Alongs: \n",
    "\n",
    "1) On your GPU, repeat the Reuters Newswire Problem : leverages a LSTM together with A CNN!       \n",
    "- compare these reseults with your previous results.\n",
    "\n",
    "2) Develop another text generation model using alternate data sources: \n",
    "    (data ref options)\n",
    "     - https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
    "     - [create lyrics from your favorite artist](https://www.kaggle.com/mousehead/songlyrics/data)\n",
    "     - any other dataset of your choice! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training\n",
    "batch_size = 10\n",
    "\n",
    "'''\n",
    "Note:\n",
    "batch_size is highly sensitive.\n",
    "Only 2 epochs are needed as the dataset is very small.\n",
    "'''\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "embedding_size =100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "# Convolution!\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(MaxPooling1D(pool_length=pool_length))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
